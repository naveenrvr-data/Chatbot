{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrAavuR7IobvYefjO4o61h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveenrvr-data/DataBot/blob/main/DataBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJtir1akeOPz"
      },
      "outputs": [],
      "source": [
        "import bs4 as bs\n",
        "import warnings\n",
        "import urllib.request\n",
        "import nltk\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import wordnet\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import wordnet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBqE593heR43",
        "outputId": "a3ba09cf-e392-452e-ba53-db5739529296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "-TVKEpMDeWpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synonyms = []\n",
        "for syn in wordnet.synsets('hello'):\n",
        "    for lem in syn.lemmas():\n",
        "        lem_name = re.sub(r'\\[[0-9]*\\]', ' ', lem.name())\n",
        "        lem_name = re.sub(r'\\s+', ' ', lem.name())\n",
        "        synonyms.append(lem_name)"
      ],
      "metadata": {
        "id": "s6ndS8PteZll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs for greeting\n",
        "greeting_inputs = ['hey', 'whats up', 'good morning', 'good evening', 'happy morning','morning', 'evening', 'hello there', 'hey there']\n",
        "# concatenating the synonyms and the inputs for greeting\n",
        "greeting_inputs = greeting_inputs + synonyms\n",
        "\n",
        "# greeting outputs by the bot\n",
        "greeting_outputs = ['Hello! How can I help you?',\n",
        "                      'Hey there! So what do you want to know?',\n",
        "                      'Hi, you can ask me anything regarding Data Science.',\n",
        "                      'Hey! wanna know about Data Science ? Just ask']\n",
        "\n",
        "\n",
        "# inputs for a Chats\n",
        "chat_inputs = ['how are you', 'how are you doing', 'you good']\n",
        "\n",
        "# Chat output by the bot\n",
        "chat_output = ['Great! what about you?']\n",
        "# Chat replies by the user\n",
        "chat_replies = ['great', 'i am fine', 'fine', 'good', 'super', 'superb', 'super great', 'nice']\n",
        "# few limited questions and answers given as dictionary\n",
        "question_answers = {'what are you': 'I am a data-bot',\n",
        "                    'who are you': 'I am a data-bot',\n",
        "                    'what can you do': 'Answer questions regarding Data Science!',\n",
        "                    'what do you do': 'Answer questions regarding Data Science!'}"
      ],
      "metadata": {
        "id": "b2miK5hgeeAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetching html data about Data Science from wiki\n",
        "data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Data_science')\n",
        "# processing the raw html into more readable data\n",
        "data = data.read()"
      ],
      "metadata": {
        "id": "LEFCTs9MepSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "_udRLaeAgoOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting html into text\n",
        "article = bs.BeautifulSoup(data, 'lxml')\n",
        "\n"
      ],
      "metadata": {
        "id": "KPBvErleeucq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article"
      ],
      "metadata": {
        "id": "-wzTUsIvrt67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting paras from the above xml and concatenating with article_text\n",
        "paragraphs = article.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for p in paragraphs:\n",
        "    article_text += p.text\n",
        "\n",
        "article_text = article_text.lower()"
      ],
      "metadata": {
        "id": "ZbUB-tp9rsjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_text"
      ],
      "metadata": {
        "id": "lfd9pzGfsF-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting rid of all the special characters\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)\n"
      ],
      "metadata": {
        "id": "hM5Y6A18e0Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting sentences from the article\n",
        "sentences = nltk.sent_tokenize(article_text)\n",
        "# extracting words from the article\n",
        "words = nltk.word_tokenize(article_text)\n",
        "\n",
        "lemma = nltk.stem.WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "RYCoJmEZe8wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatizing words for data pre-processing\n",
        "def perform_lemmatization(tokens):\n",
        "    return [lemma.lemmatize(token) for token in tokens]\n",
        "\n",
        "\n",
        "# removing punctuation\n",
        "remove_punctuation = dict((ord(punc), None) for punc in string.punctuation)\n"
      ],
      "metadata": {
        "id": "xO83Xs43e_wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# function to pre-process all the tokens from the above functions\n",
        "def processed_data(document):\n",
        "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(remove_punctuation)))\n",
        "\n",
        "\n",
        "# function for punctuation removal\n",
        "def punc_remove(str):\n",
        "    punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    no_punct = ''\n",
        "\n",
        "    for char in str:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char\n",
        "\n",
        "    return no_punct"
      ],
      "metadata": {
        "id": "iWSilfpvfELc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to generate an output to greetings\n",
        "def generate_greeting_output(hello):\n",
        "    if punc_remove(hello.lower()) in greeting_inputs:\n",
        "        return random.choice(greeting_outputs)\n",
        "\n",
        "\n",
        "# function to generate an output to chats\n",
        "def generate_chat_output(str):\n",
        "    if punc_remove(str.lower()) in chat_inputs:\n",
        "        return random.choice(chat_output)"
      ],
      "metadata": {
        "id": "Cp-cqEzffJAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a answers to questions\n",
        "def generate_answers(str):\n",
        "    if punc_remove(str.lower()) in question_answers:\n",
        "        return question_answers[punc_remove(str.lower())]"
      ],
      "metadata": {
        "id": "CGN63V6WfM2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate response to queries regarding Data Science\n",
        "def generate_response(user):\n",
        "    datarobo_output = ''\n",
        "    sentences.append(user)\n",
        "\n",
        "    word_vectorizer = TfidfVectorizer(tokenizer=processed_data, stop_words='english')\n",
        "    all_word_vectors = word_vectorizer.fit_transform(sentences)\n",
        "    similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
        "    similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
        "\n",
        "    matched_vector = similar_vector_values.flatten()\n",
        "    matched_vector.sort()\n",
        "    vector_matched = matched_vector[-2]\n",
        "\n",
        "    if vector_matched == 0.0:\n",
        "        datarobo_output = datarobo_output + 'Sorry, my database doesn\\'t have the response. Please try ' \\\n",
        "                                                'something different that is related to Data Science '\n",
        "        return datarobo_output\n",
        "    else:\n",
        "        datarobo_output = datarobo_output + sentences[similar_sentence_number]\n",
        "        return datarobo_output"
      ],
      "metadata": {
        "id": "M3bvH14EfQXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chatting with the databot -->\n",
        "chat = True\n",
        "print('Hi! I am DataRobo. You can ask me anything regarding Data Science and I shall try answering them: ')\n",
        "while chat:\n",
        "    user_input = input().lower()\n",
        "    user_input = punc_remove(user_input)\n",
        "    if user_input != 'bye':\n",
        "        if user_input == 'thanks' or user_input == 'thank you very much' or user_input == 'thank you':\n",
        "            chat = False\n",
        "            print('DataRobo: Welcome, Any time...')\n",
        "        elif user_input in chat_replies:\n",
        "            print('That\\'s nice! How may I assist you')\n",
        "            continue\n",
        "        else:\n",
        "            if generate_greeting_output(user_input) is not None:\n",
        "                print('DataRobo: ' + generate_greeting_output(user_input))\n",
        "            elif generate_chat_output(user_input) is not None:\n",
        "                print('DataRobo: ' + generate_chat_output(user_input))\n",
        "            elif generate_answers(user_input) is not None:\n",
        "                print('DataRobo: ' + generate_answers(user_input))\n",
        "            else:\n",
        "                print('DataRobo: ', end='')\n",
        "                print(generate_response(user_input))\n",
        "                sentences.remove(user_input)\n",
        "    else:\n",
        "        chat = False\n",
        "        print('DataRobo: Bye Bye, take care!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKOV4MQZfWLm",
        "outputId": "e1cb13a9-9b53-4079-a2b2-74f4a2b9c283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi! I am DataRobo. You can ask me anything regarding Data Science and I shall try answering them: \n",
            "data\n",
            "DataRobo: this can involve tasks such as data cleaning, data visualization, and exploratory data analysis to gain insights into the data and develop hypotheses about relationships between variables.\n",
            "data science\n",
            "DataRobo: however, data science is different from computer science and information science.\n",
            "cell phone\n",
            "DataRobo: Sorry, my database doesn't have the response. Please try something different that is related to Data Science \n",
            "who is a data scientist\n",
            "DataRobo: a data scientist is a professional who creates programming code and combines it with statistical knowledge to create insights from data.\n",
            "what is data cleaning\n",
            "DataRobo: this can involve tasks such as data cleaning, data visualization, and exploratory data analysis to gain insights into the data and develop hypotheses about relationships between variables.\n",
            "statistics is data science\n",
            "DataRobo: however, data science is different from computer science and information science.\n",
            "statistics\n",
            "DataRobo: he describes data science as an applied field growing out of traditional statistics.\n",
            "thank you\n",
            "DataRobo: Welcome, Any time...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6comilHy9xzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}